# LLM Provider Configuration
# Choose one of: deepseek, openai, anthropic, ollama
# Default: deepseek (you can still switch providers anytime from the UI)
LLM_PROVIDER=deepseek

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o

# Anthropic Configuration (Default Provider)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Ollama Configuration (for local models)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3:1.7b

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True

# DeepSeek (OpenAI-compatible) Configuration
# Default Provider
# DeepSeek is OpenAI-compatible and set as the default provider above.
# Provide your API key below; you may leave other providers blank if unused.
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_MODEL=deepseek-chat

# Other providers are optional â€“ keep their keys empty if not used.