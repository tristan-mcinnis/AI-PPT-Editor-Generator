# LLM Provider Configuration
# Choose one of: openai, anthropic, ollama
# Default: anthropic
LLM_PROVIDER=anthropic

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o

# Anthropic Configuration (Default Provider)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Ollama Configuration (for local models)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3:1.7b

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True